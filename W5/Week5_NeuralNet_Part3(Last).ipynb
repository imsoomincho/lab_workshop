{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week6_NeuralNet_Part3(Last).ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonlee78/lab_workshop/blob/master/W5/Week5_NeuralNet_Part3(Last).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjPNOsYrTgLZ",
        "colab_type": "text"
      },
      "source": [
        "# DeepNLP\n",
        "## hfpsych lab workshop\n",
        "### 2019.7.26 Fri.\n",
        "\n",
        "## 3.5. 출력층 설계하기\n",
        "### 3.5.1. 항등 함수와 소프트맥스 함수 구현하기\n",
        "### 3.5.2. 소프트맥스 함수 구현 시 주의점\n",
        "### 3.5.3. 소프트맥수 함수의 특징\n",
        "### 3.5.4. 출력층의 뉴런 수 정하기 \n",
        "## 3.6. 손글씨 숫자 인식\n",
        "### 3.6.2. 신경망의 추론 처리\n",
        "### 3.6.3. 배치 처리 \n",
        "## 3.7. 정리 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD9N6i_YDTS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GEadfNZD2Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('deep-learning-from-scratch/ch03')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlslRgQ8Uv2T",
        "colab_type": "text"
      },
      "source": [
        "### 3.5. 출력층 설계하기 \n",
        "\n",
        "- [Winter 2019 workshop 복습] Introduction to Machine Learning (by Andrew Ng)  : Chapter 01. Introduction \n",
        "    - Machine Learning : Regression vs Classification\n",
        "    << 그림 >>\n",
        "\n",
        "신경망은 분류와 회귀 모두에 이용할 수 있으나, 둘 중 어떤 문제냐에 따라 츨력층에서 사용하는 활성화 함수 (&sigma;)가 달라진다. 일반적으로 **회귀**에는 **항등 함수**를, **분류**에는 **소프트맥스 함수**를 사용한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ngycas-WqSz",
        "colab_type": "text"
      },
      "source": [
        "#### 3.5.1. 항등 함수와 소프트맥스 함수 구현하기\n",
        "\n",
        "\n",
        "**항등 함수** (identity function)는 입력을 그대로 출력한다. \n",
        "\n",
        "\n",
        "#### 그림 3-21. 항등 함수 ( PPT)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIXIViNldOUy",
        "colab_type": "text"
      },
      "source": [
        "#### 수식 3.10 소프트맥스 함수\n",
        "\n",
        "\\begin{equation*}\n",
        "y_{k} = \\frac{exp(a_{k})}{\\sum_{i=1}^{n} exp(a_{i})}\n",
        "\\end{equation*}\n",
        "\n",
        "exp(x) = _e_<sup>k</sup> 지수함수 (exponential function) <br>\n",
        "_e_ = 자연상수 <br>\n",
        "n = 출력층의 뉴런 수 <br>\n",
        "y<sub>_k_</sub> 그 중 k번째 출력 <br>\n",
        "\n",
        "분자: exp(_a_<sub>_k_</sub>) = 입력 신호 _a_<sub>_k_</sub>의 지수 함수  \n",
        "분모: 모든 입력 신호의 지수 함수의 합\n",
        "\n",
        "- 모든 입력 신호(input)로부터 화살표를 받는다. 분모에서 알 수 있듯이 출력층의 각 뉴런이 모든 입력 신호에서 영향을 받기 때문이다. \n",
        "\n",
        "\n",
        "#### 소프트맥스 함수 시각화\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyOxgwAdg_g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5m5oUmjfuyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "\n",
        "exp_a = np.exp(a) #지수 함수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9su_pb2Hg6-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(exp_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYI3MhH1g8zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#지수 함수의 합\n",
        "sum_exp_a = np.sum(exp_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KemEZG5xhKA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sum_exp_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrMnCYnMhMbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = exp_a / sum_exp_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwt-n4SkhOiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqdtUmkvhPKW",
        "colab_type": "text"
      },
      "source": [
        "### 3.5.2. 소프트맥스 함수 구현 시 주의점\n",
        "\n",
        "컴퓨터로 소프트맥스를 계산할 때 오버플로 문제가 발생할 수 있음. \n",
        "\n",
        "오버플로(Overflow) : 표현할 수 있는 수의 범위가 한정되어 너무 큰 값은 표현할 수 없음. \n",
        "\n",
        "#### 소프트맥스 함수를 개선한 수식\n",
        "\n",
        "[3.11.1] \\begin{equation*}\n",
        "y_{k} = \\frac{exp(a_{k})}{\\sum_{i=1}^{n} exp(a_{i})} = \\frac{C exp(a_{k})}{C \\sum_{i=1}^{n} exp(a_{i})}\n",
        "\\end{equation*}\n",
        "\n",
        "[3.11.2]\n",
        "\\begin{equation*}\n",
        "= \\frac{exp(a_{k}+logC)}{\\sum_{i=1}^{n} exp(a_{i}+logC)}\n",
        "\\end{equation*}\n",
        "\n",
        "[3.11.3]\n",
        "\\begin{equation*}\n",
        "= \\frac{exp(a_{k}+C')}{\\sum_{i=1}^{n} exp(a_{i}+C')}\n",
        "\\end{equation*}\n",
        "\n",
        "3.11.1에서는 C라는 임의의 정수를 분자와 분모 양쪽에 곱함 (양쪽에 같은 수를 곱했으니 결국 똑같은 계산)\n",
        "\n",
        "3.11.2.에서 C를 지수 함수 exp() 안으로 옮겨 logC로 만들음. 마지막으로 logC를 C라는 새로운 기호로 바꿈\n",
        "\n",
        "[식 3.11]이 말하는 것은 소프트맥스의 지수 함수를 계산할 때 어떤 정수를 더해도 (혹은 빼도) 결과는 바뀌지 않는다는 것. 여기서 C'에 어떤 값을 대입해도 상관없으나, 오버플로를 막을 목적으로는 입력 신호 중 최댓값을 이용하는 것이 일반적이다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGpEO3ghDmsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([1010, 1000, 990])\n",
        "np.exp(a) / np.sum(np.exp(a)) #소프트맥스 함수의 계산"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqej-A7nD_Yu",
        "colab_type": "text"
      },
      "source": [
        "아무런 조치 없이 계산하면 nan이 나옴. nan = not a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3MQU5DDt07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = np.max(a) #C의 최댓값"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwXF01gVDvAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a - c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn9feUDbD4LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.exp(a - c) / np.sum(np.exp(a - c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8THuYKAD7qK",
        "colab_type": "text"
      },
      "source": [
        "하지만 입력 신호 중 최댓값(=c)을 빼주면 바르게 계산 가능하다. 이를 바탕으로 소프트맥스를 다시 구현하면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BwF4KSAEKkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a-c) # 오버플로 대책\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaYHy4nEMnX",
        "colab_type": "text"
      },
      "source": [
        "### 3.5.3. 소프트맥수 함수의 특징\n",
        "\n",
        "softmax()함수를 사용하면 신경망의 출력은 다음과 같이 계산 가능하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1pD89WEUCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "y = softmax(a)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Jv8VyXEaCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X01pbWmEbbn",
        "colab_type": "text"
      },
      "source": [
        "이 성질 덕분에 softmax()함수의 출력을 '확률'로 해석 가능하다. 가령 앞의 예에서 y[0]의 확률은 0.018(1.8%), y[1]의 확률은 0.245(24.5%), y[2]의 확률은 0.737로 해석할 수 있다. 그리고 이 결과 확률들로부터 \"2번째 원소의 확률이 가장 높으니 답은 2번째  클래스다\"라고 할 수 있다. 또는 \"74%의 확률로 2번째 클래스, 25% 확률로 1번째 클래스, 1%의 확률로 0번째 클래스다\"와 같이 확률적인 결론도 낼 수 있다. 즉, 소프트맥수 함수를 이용함으로써 문제를 **확률적(통계적)으로 대응할 수 있다**. \n",
        "\n",
        "**주의** 소프트맥스 함수는 단조 증가 함수 (정의역 원소 a,b가 a<=b일때 f(a)<=f(b)가 성립하는 함수). 실제로 앞의 예에서 a의 원소들의 대소 관계가 y 의 원소들 사이의 대소 관계로 그대로 이어진다. 예를 들어 a에서 가장 큰 원소는 2번째 원소이고, y에서 가장 큰 원소도 2번째 원소이다. \n",
        "\n",
        "기계학습의 문제 풀이는 **학습**과 **추론( reference)** 으로 나뉜다. 학습 단계에서는 모델을 학습하고, 추론 단계에서는 앞서 학습한 모델로 미지의 데이터에 대해서 추론(분류)를 수행한다. 보통 추론 단계에서는 출력층의 소프트맥스 함수를 생략하는 것이 일반적이고 학습 단계에서는 출력층에서 소프트맥스 함수를 사용한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObpD2AYwFlue",
        "colab_type": "text"
      },
      "source": [
        "### 3.5.4. 출력층의 뉴런 수 정하기\n",
        "\n",
        "#### 그림 3-23. 출력층의 뉴런은 각 숫자에 대응한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbQdLzkmGJGF",
        "colab_type": "text"
      },
      "source": [
        "### 3.6. 손글씨 숫자 인식\n",
        "\n",
        "### 3.6.1. MNIST 데이터셋\n",
        "\n",
        "이번 예에서 사용하는 데이터셋은 MNIST라는 손글씨 숫자 이미지 집합이다. \n",
        "\n",
        "- 구성: 0 ~ 9까지의 숫자 이미지. 훈련 이미지: 60,000장, 시험 이미지: 10,000장. \n",
        "\n",
        "wiki: https://en.wikipedia.org/wiki/MNIST_database\n",
        "\n",
        "훈련 이미지로 모델을 학습한 후, 시험 이미지들을 얼마나 정확하게 분류하는지를 평가\n",
        "\n",
        "MNIST의 이미지 데이터는 28 X 28 크기의 회색조 이미지, 각 픽셀 값은 0~255. 각 이미지에는 실제 의미하는 숫자가 레이블로 붙어 있음\n",
        "\n",
        "mnist.py 파일에 정의된 load_mist()함수를 이용하면 데이터 로드 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh8lEvN2QyHR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "import sys, os\n",
        "sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "from dataset.mnist import load_mnist\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBBSE10mRGqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### 참고:  tensorflow 에도 내장되어 있음  - 지금은 skip. \n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Read data\n",
        "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJTL3C-R-_GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#필요하지 않은 경우 skip할 것\n",
        "#!wget https://raw.githubusercontent.com/WegraLee/deep-learning-from-scratch/master/dataset/mnist.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L0rq0O68Hcq",
        "colab_type": "text"
      },
      "source": [
        "The code uses built-in capabilities of TensorFlow to download the dataset locally and load it into the python variable. As a result (if not specified otherwise), the data will be downloaded into the MNIST_data/ folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omcr6HID_P2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir dataset #필요하지 않은 경우 skip할 것"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfiXd8WU_fhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mv mnist.py dataset #필요하지 않은 경우 skip할 것"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKqGt_IqXF_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "# 처음 한 번은 몇 분 정도 걸립니다.\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "# 각 데이터의 형상 출력\n",
        "print(x_train.shape) # (60000, 784)\n",
        "print(t_train.shape) # (60000,)\n",
        "print(x_test.shape)  # (10000, 784)\n",
        "print(t_test.shape)  # (10000,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqExbvJQVYTn",
        "colab_type": "text"
      },
      "source": [
        "```load_mnist```함수는 읽은 MNIST 데이터를 \"(훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\"형식으로 반환한다. 인수로는 normalize, flatten, one_hot_label 3가지를 설정한다. \n",
        "\n",
        "3개의 인수 모두 bool 값이다. \n",
        "\n",
        "1. normalize : 입력 이미지의 픽셀 값을 0.0 ~ 1.0 사이의 값으로 정규화할지를 정한다. False로 설정할 경우 입력 이미지의 픽셀은 원래 값 그대로 0~255 사이의 값을 유지한다. \n",
        "\n",
        "2. flatten : 입력 이미지를 평탄하게 (1차원 배열로) 만들지를 정한다. False로 설정하면 입력 이미지를 1x28x28의 3차원 배열로, True로 설정하면 784개의 원소로 이루어진 1차원 배열로 저장한다. \n",
        "\n",
        "3. one_hot_label : 레이블을 **원-핫-인코딩<sup>one-hot encoding</sup>** 형태로 저장할지를 정한다.  원 핫 인코딩은 정답을 뜻하는 원소만 1이고 (hot하고) 나머지는 모두 0인 배열이다 (예: [0,0,1,0,0,0,0,]). one_hot_label이 False이면 '7'이나 '2'와 같이 숫자 형태의 레이블을 저장하고, True일 경우 원-핫-인코딩된 레이블을 저장한다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzlCYPTWdNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from PIL import Image\n",
        "\n",
        "def img_show(img):\n",
        "    pil_img = Image.fromarray(np.uint8(img))\n",
        "    pil_img.show()\n",
        "    plt.imshow(np.array(pil_img))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTUYR63dB0g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "\n",
        "print(label) # 5\n",
        "\n",
        "print(img.shape)          # (784,)\n",
        "img = img.reshape(28, 28) # 원래 이미지의 모양으로 변형\n",
        "print(img.shape)          # (28, 28)\n",
        "\n",
        "img_show(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M13OAq3RXAPU",
        "colab_type": "text"
      },
      "source": [
        "**주의** flatten = True 로 설정해 읽어 들인 이미지는 1차원 넘파이 배열로 저장되어 있음. 따라서 이미지를 표시할 때는 원래 형상인 28 * 28 크기로 다시 변형해야한다. reshape() 메서드에 원하는 형상을 인수로 정하면 넘파이 배열의 형상을 바꿀 수 있다. 또한, 넘파이로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환해야하며 이는 Image.fromarray()가 수행한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZIvpJSSXqt7",
        "colab_type": "text"
      },
      "source": [
        "### 3.6.3. 신경망의 추론 처리 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsCfXWQCXtmJ",
        "colab_type": "text"
      },
      "source": [
        "입력 뉴런을 784개, 출력층 뉴런을 10개로 구성한다. \n",
        "첫 번째 은닉층은 50개의 뉴런, 두 번째 은닉층은 100개의 뉴런을 배치한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxCZg6oVX1Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label = False)\n",
        "    return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    \n",
        "    return network\n",
        "\n",
        "def predict(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "    \n",
        "    a1 = np.dot(x, W1) + b1 #1층 레이어의 가중치 합\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2 #2층 레이어의 가중치 합\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3 #3층 레이어의 가중치 합\n",
        "    y = softmax(a3) #최종 출력\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k3VKfrZYBRZ",
        "colab_type": "text"
      },
      "source": [
        "init_network()에는 pickle파일인 sample_weight.pkl에 저장된 '학습된 가중치 매개변수'를 읽는다. 이 파일에는 가중치와 편향 매개 변수가 딕셔너리 변수로 저장되어 있다. pickle은 이럴 때 아주 유용한 파이썬 메소드이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrn4J5szYQ_e",
        "colab_type": "text"
      },
      "source": [
        "위에 정의한 함수들로 신경망에 의한 추론을 수행해보고 **정확도**<sup>accuracy</sup>(분류가 얼마나 올바른가)도 평가해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlEpYLqHEqRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW6BpZyQYgSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "accuracy_cnt = 0\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻음\n",
        "    if p == t[i]:\n",
        "        accuracy_cnt += 1\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa7w4zD5Yi_Y",
        "colab_type": "text"
      },
      "source": [
        "1. MNIST 데이터셋으로 네트워크 생성\n",
        "\n",
        "2. for문을 돌면서 x에 저장된 이미지 데이터를 1장씩 꺼내 predict()함수로 분류. \n",
        "\n",
        "-- **predict()** : 각 레이블의 확률을 넘파이 배열로 반환\n",
        "\n",
        "3. np.argmax()함수로 이 배열에서 값이 가장 큰 (확률이 가장 높은) 원소의 인덱스를 구함 (= 예측 결과)\n",
        "\n",
        "4.  신경망이 예측한 답변과 정답 레이블을 비교하여 맞힌 숫자(accuracy_cnt)를 세고, 전체 이미지 숫자로 나눠 정확도 계산\n",
        "\n",
        "**정규화(normalize)** : 데이터를 특정 범위로 변환하는 처리\n",
        "\n",
        "여기서는 normalize를 True로 설정. 각 픽셀의 값을 0.0~1.0 범위로 변환.\n",
        "\n",
        "  - 데이터 전체 평균과 표준편차를 이용하여 데이터들이 0을 중심으로 분포하도록 이동시킴\n",
        "\n",
        "   - 데이터의 확산 범위를 제한하는 정규화를 수행\n",
        "\n",
        "**전처리(pre-processing)**: 신경망의 입력 데이터에 특정 변환을 가하는 것 (위 정규화를 포함)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdIM5Sz6Ymh-",
        "colab_type": "text"
      },
      "source": [
        "### 3.6.3. 배치 처리\n",
        "\n",
        "각 층의 가중치 형상을 출력 (W)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL_W27ICYsr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, _ = get_data()\n",
        "network = init_network()\n",
        "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FetkI-gZYvI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MgdfgRXYwOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd-qfvPsYw31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ47u3UGYxmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W3.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1bi2snFYyfS",
        "colab_type": "text"
      },
      "source": [
        "최종 결과: 원소가 10개인 1차원 배열 Y가 출력된다. \n",
        "\n",
        "#### 그림 3-26.\n",
        "#### 그림 3-27\n",
        "\n",
        "- 입력 데이터 형상(shape)은 100 * 784, 출력 데이터의 형상(shape)은 100 * 10이다. \n",
        "-  100장 분량의 입력 데이터의 결과가 한 번에 출력됨 ( 배치)\n",
        "\n",
        "- **배치**: 하나로 묶은 데이터\n",
        "\n",
        "- 배치 처리의 장점 : 이미지 1장당 처리 시간을 대폭 줄임\n",
        "\n",
        "  -- 수치 계산 라이브러리 대부분이 큰 배열을 효율적으로 계산함\n",
        "\n",
        "  -- 버스에 주는 부하를 줄임( = 느린 I/O를 통해 데이터를 읽는 횟수가 줄어, CPU, GPU로 순수 계산을 수행하는 비율이 높아짐)\n",
        "  \n",
        "  -- 컴퓨터에서는 큰 배열을 한꺼번에 계산하는 것이 분할된 작은 배열을 여러 번 계산하는 것보다 빠르다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTHaOzML14Er",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### 배치 처리 구현 (다음 장 4. 신경망 학습에서 4.2.3. 미니배치 학습할 때 방문)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtCuP5asY2mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 # 배치 크기 (1)\n",
        "accuracy_cnt = 0\n",
        "for i in range(0, len(x), batch_size): #for문 (2)\n",
        "    x_batch = x[i:i+batch_size] #입력 데이터의 i번째부터 i+batch_size번째까지의 데이터를 묶음\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGaleK9cZJd_",
        "colab_type": "text"
      },
      "source": [
        "```range(start, end, step)``` 처럼 인수를 3개 지정하면 start에서 end-1까지 step 간격으로 증가하는 리스트를 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC1cwHuNZMmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list( range(0, 10) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HRRNydrZT0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list( range(0, 10, 3) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiWxgn_UZUMV",
        "colab_type": "text"
      },
      "source": [
        "range()함수가 반환하는 리스트를 바탕으로 x[i:i+batch_n]에서 입력데이터를 묶음\n",
        "    -- x 입력 데이터 i번째부터 i+batch_n번째까지 데이터를 묶는다는 의미\n",
        "\n",
        "- batch_size가 100이므로 x[0:100], x[100:200]와 같이 100장씩 묶어 꺼냄. \n",
        "\n",
        "- argmax(): 최대값의 인덱스를 가져옴\n",
        "\n",
        "- axis=1 인수를 추가한 것에 주의: **100 X 10의 배열 중 1번째 차원을 구성하는 각 원소에서(1번째 차원을 축으로) 최대값의 인덱스를 찾도록 한 것** (아래 예시 참조)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INqZekpqZX8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#argmax axis 예시\n",
        "\n",
        "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
        "y = np.argmax(x, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp9VRpEzZZv8",
        "colab_type": "text"
      },
      "source": [
        "#### 배치 단위로 분류된 결과를 실제 답과 비교. \n",
        "\n",
        "비교를 위해 ==연산자 사용\n",
        "\n",
        "넘파이 배열끼리 비교하여 True/False로 구성된 bool 배열을 생성, 이 결과 배열에서 True가 몇 개인지 카운트함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Jx58IZZb3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#True 개수를 센다 \n",
        "y = np.array([1, 2, 1, 0])\n",
        "t = np.array([1, 2, 0, 0])\n",
        "print(y==t)\n",
        "np.sum(y==t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4a-00d5ZdTu",
        "colab_type": "text"
      },
      "source": [
        "### 3.7 정리 \n",
        "### Chapter 03.에서 배운 내용 \n",
        "\n",
        "- **활성화 함수**\n",
        "\n",
        "- 신경망에서는 **활성화 함수**로 **시그모이드**를, **ReLU 함수** 같은 (비선형) 매끄럽게 변화하는 함수를 이용한다.\n",
        "\n",
        "- 넘파이의 **다차원 배열**을 잘 사용하면 신경망을 효율적으로 구현 가능하다. 다만 행렬의 곱에서는 각 형상의 행렬이 일치해야 계산이 가능하다. \n",
        "\n",
        "- 기계학습 문제는 크게 **회귀와 분류**로 나눌 수 있다. \n",
        "\n",
        "- **출력층**의 활성화 함수로 회귀에서는 주로 항등 함수, 분류에서는 주로 소프트맥스 함수를 이용한다.\n",
        "\n",
        "- 분류에서는 출력층의 뉴런 수로 분류하는 클래스 수와 같게 설정한다.\n",
        "\n",
        "- 입력 데이터를 묶은 것을 **배치**라고 한다. 추론 처리를 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5351mWuZZg2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}